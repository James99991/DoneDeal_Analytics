{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Python Info\n",
    "\n",
    "`Practical Web Scraping for Data Science: Seppe Vanden Broucke, Bart Baesens`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A : B'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Strings\n",
    "\"{} : {}\".format(\"A\", \"B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A, A, B'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{0}, {0}, {1}\".format(\"A\", \"B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Web Speaks HTTP\n",
    "\n",
    "**Steps navigating to a website**\n",
    "- You enter “www.google.com” into your web browser, which needs to figure out the IP address for this site. IP stands for “Internet Protocol” and forms a core protocol of the Internet, as it enables networks to route and redirect communication packets between connected computers, which are all given an IP address\n",
    "- And so, your browser sets off to figure out the correct IP address behind “www.google.com”\n",
    "- If the operating system is also unaware of this domain, the browser will send a DNS request to your router, which is the machine that connects you to the Internet and also — typically — keeps its own DNS cache.\n",
    "- All of this was done just to figure out the IP address of www.google.com. Your browser can now establish a connection to 172.217.17.68, Google’s web server\n",
    "- Google’s web server now sends back an HTTP reply, containing the contents of the page we want to visit. In most cases, this textual content is formatted using HTML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTTP in Python: The Requests Library\n",
    "\n",
    "> Basically, we’re throwing out our web browser and we’re going to\n",
    "surf the web using a Python program instead. This means that our Python program will\n",
    "need to be able to speak and understand HTTP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello from the web!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "url = 'http://www.webscrapingfordatascience.com/basichttp/'\n",
    "r = requests.get(url)\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "OK\n",
      "{'Keep-Alive': 'timeout=5, max=100', 'Connection': 'Keep-Alive', 'Date': 'Sat, 14 Dec 2019 11:57:40 GMT', 'Server': 'Apache/2.4.18 (Ubuntu)', 'Content-Length': '20', 'Content-Type': 'text/html; charset=UTF-8'}\n",
      "<PreparedRequest [GET]>\n",
      "{'User-Agent': 'python-requests/2.13.0', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Connection': 'keep-alive'}\n",
      "Hello from the web!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Take a look under the hood\n",
    "import requests\n",
    "url = 'http://www.webscrapingfordatascience.com/basichttp/'\n",
    "r = requests.get(url)\n",
    "\n",
    "# Which HTTP status code did we get back from the server?\n",
    "print(r.status_code)\n",
    "# What is textual status code?\n",
    "print(r.reason)\n",
    "# What were the HTTP response headers?\n",
    "print(r.headers)\n",
    "# The request information is saved as a Python object in r.request:\n",
    "print(r.request)\n",
    "# What were the HTTP request headers?\n",
    "print(r.request.headers)\n",
    "# The HTTP response content:\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here, a status code and message of “200 OK” indicates that everything went well.\n",
    "- The headers attribute of the request.Response object returns a dictionary of the headers the server included in its HTTP reply. This server reports its data, server version, and also provides the “Content-Type” header.\n",
    "- To get information regarding the HTTP request that was fired off, you can access the request attribute of a request.Response object. This attribute itself is a request.Request object, containing information about the HTTP request that was prepared.\n",
    "- Since an HTTP request message also includes headers, we can access the headers attribute for this object as well to get a dictionary representing the headers that were included by requests. Note that requests politely reports its “User-Agent” by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "OK\n",
      "{'Keep-Alive': 'timeout=5, max=100', 'Connection': 'Keep-Alive', 'Date': 'Sat, 14 Dec 2019 12:05:45 GMT', 'Server': 'Apache/2.4.18 (Ubuntu)', 'Content-Length': '34', 'Content-Type': 'text/html; charset=UTF-8'}\n",
      "<PreparedRequest [GET]>\n",
      "{'User-Agent': 'python-requests/2.13.0', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Connection': 'keep-alive'}\n",
      "Please provide a \"query\" parameter\n"
     ]
    }
   ],
   "source": [
    "# Take a look under the hood\n",
    "import requests\n",
    "url = 'http://www.webscrapingfordatascience.com/paramhttp/'\n",
    "r = requests.get(url)\n",
    "\n",
    "# Which HTTP status code did we get back from the server?\n",
    "print(r.status_code)\n",
    "# What is textual status code?\n",
    "print(r.reason)\n",
    "# What were the HTTP response headers?\n",
    "print(r.headers)\n",
    "# The request information is saved as a Python object in r.request:\n",
    "print(r.request)\n",
    "# What were the HTTP request headers?\n",
    "print(r.request.headers)\n",
    "# The HTTP response content:\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try opening this page in your web browser to verify that you get the same result. Now try navigating to the page http://www.webscrapingfordatascience.com/paramhttp/? query=test. \n",
    "\n",
    "What do you see?\n",
    "\n",
    "The optional “?…” part in URLs is called the “query string,” and it is meant to contain data that does not fit within a URL’s normal hierarchical path structure. You’ve probably\n",
    "encountered this sort of URL many times when surfing the web, for example:\n",
    "- http://www.example.com/product_page.html?product_id=304\n",
    "- https://www.google.com/search?dcr=0&source=hp&q=test&oq=test\n",
    "- http://example.com/path/to/page/?type=animal&location=asia\n",
    "\n",
    "Query strings in URLs should adhere to the following conventions:\n",
    "- A query string comes at the end of a URL, starting with a single question mark, “?”.\n",
    "- Parameters are provided as key-value pairs and separated by an ampersand, “&”.\n",
    "- The key and value are separated using an equals sign, “=”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stirring the HTML and CSS Soup\n",
    "\n",
    "`Chapter 3`\n",
    "- HTML tags often come in pairs and are enclosed in angled brackets, with `<tagname>` being the opening tag and `</tagname>` indicating the closing tag. Some tags come in an unpaired form, and do not require a closing tag. Some commonly used tags are the following:\n",
    "\n",
    "- Most modern web browsers nowadays include a toolkit of powerful tools you can use to get an idea of what’s going on regarding HTML, and HTTP too.\n",
    "\n",
    "**You might wonder why the “View source” option is useful to look at a page’s raw HTML source when we have a much user-friendlier alternative offered by the Elements tab.**\n",
    "\n",
    "- A warning is in order here: the “View source” option shows the HTML code *as it was returned by the web server*, and it will contain the **same contents as r.text** when using requests. \n",
    "\n",
    "- The view in the Elements tab, on the other hand, provides a “cleaned up” version after the HTML was parsed by your web browser. Overlapping tags are fixed and extra white space is removed, for instance. There might hence be small differences between these two views. \n",
    "- In addition, the Elements tab provides a live and dynamic view. Websites can include scripts that are executed by your web browser and which can alter the contents of the page at will. The Elements tab will hence always reflect the current state of the page.\n",
    "\n",
    "\n",
    "\n",
    "- Next, note that any HTML element in the Elements tab can be right-clicked. “Copy, Copy selector” and “Copy XPath” are particularly useful, which we’re going to use quite often later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cascading Style Sheets: CSS\n",
    "\n",
    "While\n",
    "perusing the HTML elements in your browser, you’ve probably noticed that some HTML\n",
    "attributes are present in lots of tags:\n",
    "\n",
    "- id\n",
    "- class\n",
    "\n",
    "In CSS, style information\n",
    "is written down as a list of colon-separated key-value based statements, with each\n",
    "statement itself being separated by a semicolon, as follows:\n",
    "\n",
    "- color: 'red':\n",
    "- font-size: 14pt:\n",
    "- ...\n",
    "\n",
    "These style declarations can be included in a document in three different ways: - **see page 57 for more details**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Beautiful Soup Library\n",
    "\n",
    "Beautiful Soup tries to organize complexity: it helps to parse,\n",
    "structure and organize the oftentimes very messy web by fixing bad HTML and\n",
    "presenting us with an easy-to-work-with Python structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful Soup’s main task is to take HTML content and transform it into a tree-based\n",
    "representation. Once you’ve created a BeautifulSoup object, there are two\n",
    "methods you’ll be using to fetch data from the page:\n",
    "\n",
    "• `find(name, attrs, recursive, string, **keywords);`\n",
    "\n",
    "• `find_all(name, attrs, recursive, string, limit, **keywords).`\n",
    "\n",
    "**Both find and find_all return Tag objects. Using these, there are a number of\n",
    "interesting things you can do:**\n",
    "\n",
    "- Access the name attribute to retrieve the tag name.\n",
    "- Access the contents attribute to get a Python list containing the tag’s children (its direct descendant tags) as a list.\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://en.wikipedia.org/w/index.php' + \\\n",
    "'?title=List_of_Game_of_Thrones_episodes&oldid=802553687'\n",
    "\n",
    "r = requests.get(url)\n",
    "html_contents = r.text\n",
    "html_soup = BeautifulSoup(html_contents, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1\n",
      "['List of ', <i>Game of Thrones</i>, ' episodes']\n",
      "<h1 class=\"firstHeading\" id=\"firstHeading\" lang=\"en\">List of <i>Game of Thrones</i> episodes</h1>\n",
      "List of Game of Thrones episodes\n",
      "List of Game of Thrones episodes\n",
      "{'lang': 'en', 'class': ['firstHeading'], 'id': 'firstHeading'}\n",
      "firstHeading\n",
      "firstHeading\n",
      "firstHeading\n",
      "------------ CITATIONS ------------\n",
      "Fowler, Matt (April 8, 2011). \"Game of Thrones: \"Winter is Coming\" Review\". IGN. Archived from the original on August 17, 2012. Retrieved September 22, 2016.\n",
      "Fleming, Michael (January 16, 2007). \"HBO turns Fire into fantasy series\". Variety. Archived from the original on May 16, 2012. Retrieved September 3, 2016.\n",
      "\"Game of Thrones\". Emmys.com. Retrieved September 17, 2016.\n",
      "Roberts, Josh (April 1, 2012). \"Where HBO's hit 'Game of Thrones' was filmed\". USA Today. Archived from the original on April 1, 2012. Retrieved March 8, 2013.\n",
      "Schwartz, Terri (January 28, 2013). \"'Game of Thrones' casts a bear and shoots in Los Angeles for major Season 3 scene\". Zap2it. Archived from the original on October 16, 2013. Retrieved March 8, 2013.\n",
      "https://web.archive.org/web/20131016062544/http://blog.zap2it.com/frominsidethebox/2013/01/game-of-thrones-casts-a-bear-and-shoots-in-los-angeles-for-major-season-3-scene.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find the first h1 tag - seems to be a sort of heading\n",
    "first_h1 = html_soup.find('h1')\n",
    "\n",
    "print(first_h1.name) # h1\n",
    "\n",
    "print(first_h1.contents) # ['List of ', [...], ' episodes']\n",
    "\n",
    "print(str(first_h1))\n",
    "\n",
    "print(first_h1.text) # List of Game of Thrones episodes\n",
    "print(first_h1.get_text()) # Does the same\n",
    "\n",
    "print(first_h1.attrs)\n",
    "\n",
    "print(first_h1.attrs['id']) # firstHeading\n",
    "print(first_h1['id']) # Does the same\n",
    "print(first_h1.get('id')) # Does the same\n",
    "\n",
    "print('------------ CITATIONS ------------')\n",
    "\n",
    "# Find the first five cite elements with a citation class\n",
    "cites = html_soup.find_all('cite', class_='citation', limit=5)\n",
    "\n",
    "for citation in cites:\n",
    "    print(citation.get_text())\n",
    "    \n",
    "# Inside of this cite element, find the first a tag\n",
    "\n",
    "link = citation.find('a')\n",
    "\n",
    "# ... and show its URL\n",
    "print(link.get('href'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
